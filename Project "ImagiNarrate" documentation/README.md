# ImagiNarrate: Building a Narrative with Images and Generated Captions

## Abstract

In this paper, we introduce a new natural language processing (NLP) approach to solve the
problem of visual storytelling that utilizes image features to generate captions and subsequently
develop a coherent story line for the images. By incorporating image features in
the caption generation process, our proposed approach aims to provide a more relevant and
informative description of the images that can be used to build a cohesive and engaging narrative.
We evaluate our model in comparison to the AREL model (Wang et al., 2018) used
for story generation on the basis of traditional metrics like Meteor and Bleu as well as human
evaluation of the generated stories.

This repo contains the documentation for the Natural Language process Project "ImagiNarrate: Building a Narrative with Images and Generated Captions".
In the project, we introduce a new natural language processing (NLP) approach to solve the problem of visual storytelling that utilizes image features to generate captions and subsequently develop a coherent story line for the images.

The implementation of the project can be found [here](https://github.com/Asmita-Chotani/NLP_Paper_Implementation.git)
